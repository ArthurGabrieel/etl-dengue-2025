{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bcbefda",
   "metadata": {},
   "source": [
    "# ETL Silver ‚Üí Gold Layer\n",
    "## Data Warehouse Dengue 2025 - Star Schema\n",
    "### Nomenclatura: DICIONARIO_MNEMONICOS.md\n",
    "\n",
    "**Origem:** `public.dengue_silver` (tabela j√° transformada pelo ETL Raw‚ÜíSilver)\n",
    "\n",
    "**Destino:** Schema `gold` com Star Schema dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83500de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup conclu√≠do\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from datetime import datetime, date\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√£o do banco de dados\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'database': 'gis',\n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres'\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 50_000\n",
    "print(\"‚úÖ Setup conclu√≠do\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171c7fad",
   "metadata": {},
   "source": [
    "## 1. Conex√£o e Verifica√ß√£o Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad4b9dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Silver Layer (public.dengue_silver) - Resumo:\n",
      "   Total registros: 1,661,634\n",
      "   Per√≠odo: 2024-12-29 a 2026-01-05\n",
      "   UFs: 27\n"
     ]
    }
   ],
   "source": [
    "# Conectar ao banco\n",
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Verificar dados na Silver (public.dengue_silver)\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT COUNT(*) as total,\n",
    "           MIN(data_notificacao) as data_min,\n",
    "           MAX(data_notificacao) as data_max,\n",
    "           COUNT(DISTINCT uf_sigla) as qtd_ufs\n",
    "    FROM public.dengue_silver\n",
    "\"\"\")\n",
    "result = cursor.fetchone()\n",
    "total_silver = result[0]\n",
    "\n",
    "print(\"üìä Silver Layer (public.dengue_silver) - Resumo:\")\n",
    "print(f\"   Total registros: {total_silver:,}\")\n",
    "print(f\"   Per√≠odo: {result[1]} a {result[2]}\")\n",
    "print(f\"   UFs: {result[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cbd055",
   "metadata": {},
   "source": [
    "## 2. Carregar Dados Silver em Mem√≥ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ceb80cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Carregando dados Silver para mem√≥ria...\n",
      "‚úÖ Carregados 1,661,634 registros\n",
      "   Mem√≥ria: 920.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Query para carregar todos os dados da Silver Layer\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    id_notificacao,\n",
    "    uf_sigla,\n",
    "    data_notificacao,\n",
    "    data_sintomas,\n",
    "    data_obito,\n",
    "    ano_notificacao,\n",
    "    mes_notificacao,\n",
    "    semana_epi,\n",
    "    idade_anos,\n",
    "    faixa_etaria,\n",
    "    sexo_desc,\n",
    "    raca_desc,\n",
    "    qtd_sintomas,\n",
    "    qtd_alarmes,\n",
    "    fl_comorbidade,\n",
    "    classificacao_desc,\n",
    "    evolucao_desc,\n",
    "    fl_confirmado,\n",
    "    fl_grave,\n",
    "    fl_obito,\n",
    "    fl_hospitalizado\n",
    "FROM public.dengue_silver\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚è≥ Carregando dados Silver para mem√≥ria...\")\n",
    "df_silver = pd.read_sql(query, conn)\n",
    "print(f\"‚úÖ Carregados {len(df_silver):,} registros\")\n",
    "print(f\"   Mem√≥ria: {df_silver.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfc30aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Amostra dos dados carregados:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_notificacao</th>\n",
       "      <th>uf_sigla</th>\n",
       "      <th>data_notificacao</th>\n",
       "      <th>data_sintomas</th>\n",
       "      <th>data_obito</th>\n",
       "      <th>ano_notificacao</th>\n",
       "      <th>mes_notificacao</th>\n",
       "      <th>semana_epi</th>\n",
       "      <th>idade_anos</th>\n",
       "      <th>faixa_etaria</th>\n",
       "      <th>...</th>\n",
       "      <th>raca_desc</th>\n",
       "      <th>qtd_sintomas</th>\n",
       "      <th>qtd_alarmes</th>\n",
       "      <th>fl_comorbidade</th>\n",
       "      <th>classificacao_desc</th>\n",
       "      <th>evolucao_desc</th>\n",
       "      <th>fl_confirmado</th>\n",
       "      <th>fl_grave</th>\n",
       "      <th>fl_obito</th>\n",
       "      <th>fl_hospitalizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1514995</td>\n",
       "      <td>SP</td>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>2025-03-21</td>\n",
       "      <td>None</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>36.0</td>\n",
       "      <td>20-39 anos</td>\n",
       "      <td>...</td>\n",
       "      <td>Branca</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Dengue</td>\n",
       "      <td>Cura</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1514996</td>\n",
       "      <td>SP</td>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>2025-03-23</td>\n",
       "      <td>None</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20-39 anos</td>\n",
       "      <td>...</td>\n",
       "      <td>Branca</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Dengue</td>\n",
       "      <td>Cura</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1514997</td>\n",
       "      <td>SP</td>\n",
       "      <td>2025-03-25</td>\n",
       "      <td>2025-03-21</td>\n",
       "      <td>None</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20-39 anos</td>\n",
       "      <td>...</td>\n",
       "      <td>Branca</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Dengue</td>\n",
       "      <td>Cura</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_notificacao uf_sigla data_notificacao data_sintomas data_obito  \\\n",
       "0         1514995       SP       2025-03-25    2025-03-21       None   \n",
       "1         1514996       SP       2025-03-25    2025-03-23       None   \n",
       "2         1514997       SP       2025-03-25    2025-03-21       None   \n",
       "\n",
       "   ano_notificacao  mes_notificacao  semana_epi  idade_anos faixa_etaria  ...  \\\n",
       "0             2025                3          12        36.0   20-39 anos  ...   \n",
       "1             2025                3          12        20.0   20-39 anos  ...   \n",
       "2             2025                3          12        27.0   20-39 anos  ...   \n",
       "\n",
       "  raca_desc qtd_sintomas  qtd_alarmes  fl_comorbidade  classificacao_desc  \\\n",
       "0    Branca            5            0               0              Dengue   \n",
       "1    Branca            5            0               0              Dengue   \n",
       "2    Branca            1            0               0              Dengue   \n",
       "\n",
       "  evolucao_desc fl_confirmado  fl_grave  fl_obito  fl_hospitalizado  \n",
       "0          Cura             1         0         0                 0  \n",
       "1          Cura             1         0         0                 0  \n",
       "2          Cura             1         0         0                 0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar amostra dos dados\n",
    "print(\"üìã Amostra dos dados carregados:\")\n",
    "df_silver.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9881a7b6",
   "metadata": {},
   "source": [
    "## 3. Constru√ß√£o das Dimens√µes\n",
    "### 3.1 dim_tmp (Dimens√£o Tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c838b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Datas √∫nicas para dim_tmp: 373\n",
      "‚úÖ dim_tmp: 373 registros\n"
     ]
    }
   ],
   "source": [
    "# Dicion√°rio de dias da semana em portugu√™s\n",
    "DIAS_SEMANA = {0: 'Segunda', 1: 'Ter√ßa', 2: 'Quarta', 3: 'Quinta', 4: 'Sexta', 5: 'S√°bado', 6: 'Domingo'}\n",
    "\n",
    "# Extrair datas √∫nicas de notifica√ß√£o e sintomas\n",
    "datas_notif = pd.to_datetime(df_silver['data_notificacao'].dropna().unique())\n",
    "datas_sint = pd.to_datetime(df_silver['data_sintomas'].dropna().unique())\n",
    "datas_unicas = pd.Series(list(set(datas_notif) | set(datas_sint))).dropna().unique()\n",
    "print(f\"üìÖ Datas √∫nicas para dim_tmp: {len(datas_unicas)}\")\n",
    "\n",
    "# Construir dados da dimens√£o\n",
    "dim_tempo_data = []\n",
    "for d in sorted(pd.to_datetime(datas_unicas)):\n",
    "    data = d.date()\n",
    "    dim_tempo_data.append({\n",
    "        'dt_completa': data,\n",
    "        'nr_ano': d.year,\n",
    "        'nr_mes': d.month,\n",
    "        'nr_dia': d.day,\n",
    "        'nr_trimestre': (d.month - 1) // 3 + 1,\n",
    "        'nr_semana_epi': d.isocalendar()[1],\n",
    "        'nr_dia_semana': d.dayofweek + 1,\n",
    "        'nm_dia': DIAS_SEMANA[d.dayofweek],\n",
    "        'flag_fim_semana': d.dayofweek >= 5,\n",
    "        'ds_mes_ano': f\"{d.year}-{d.month:02d}\",\n",
    "        'ds_ano_trimestre': f\"{d.year}-Q{(d.month - 1) // 3 + 1}\"\n",
    "    })\n",
    "\n",
    "df_dim_tempo = pd.DataFrame(dim_tempo_data)\n",
    "print(f\"‚úÖ dim_tmp: {len(df_dim_tempo)} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba250de6",
   "metadata": {},
   "source": [
    "### 3.2 dim_loc (Dimens√£o Localiza√ß√£o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1bf555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó∫Ô∏è UFs encontradas: 27\n",
      "‚úÖ dim_loc: 27 registros\n"
     ]
    }
   ],
   "source": [
    "# Mapeamento de UFs para informa√ß√µes adicionais\n",
    "UFS_INFO = {\n",
    "    'AC': ('Acre', 'Norte', 12), 'AL': ('Alagoas', 'Nordeste', 27), 'AP': ('Amap√°', 'Norte', 16),\n",
    "    'AM': ('Amazonas', 'Norte', 13), 'BA': ('Bahia', 'Nordeste', 29), 'CE': ('Cear√°', 'Nordeste', 23),\n",
    "    'DF': ('Distrito Federal', 'Centro-Oeste', 53), 'ES': ('Esp√≠rito Santo', 'Sudeste', 32),\n",
    "    'GO': ('Goi√°s', 'Centro-Oeste', 52), 'MA': ('Maranh√£o', 'Nordeste', 21), 'MT': ('Mato Grosso', 'Centro-Oeste', 51),\n",
    "    'MS': ('Mato Grosso do Sul', 'Centro-Oeste', 50), 'MG': ('Minas Gerais', 'Sudeste', 31),\n",
    "    'PA': ('Par√°', 'Norte', 15), 'PB': ('Para√≠ba', 'Nordeste', 25), 'PR': ('Paran√°', 'Sul', 41),\n",
    "    'PE': ('Pernambuco', 'Nordeste', 26), 'PI': ('Piau√≠', 'Nordeste', 22), 'RJ': ('Rio de Janeiro', 'Sudeste', 33),\n",
    "    'RN': ('Rio Grande do Norte', 'Nordeste', 24), 'RS': ('Rio Grande do Sul', 'Sul', 43),\n",
    "    'RO': ('Rond√¥nia', 'Norte', 11), 'RR': ('Roraima', 'Norte', 14), 'SC': ('Santa Catarina', 'Sul', 42),\n",
    "    'SP': ('S√£o Paulo', 'Sudeste', 35), 'SE': ('Sergipe', 'Nordeste', 28), 'TO': ('Tocantins', 'Norte', 17)\n",
    "}\n",
    "\n",
    "# Extrair UFs √∫nicas dos dados\n",
    "ufs_unicas = df_silver['uf_sigla'].dropna().unique()\n",
    "print(f\"üó∫Ô∏è UFs encontradas: {len(ufs_unicas)}\")\n",
    "\n",
    "# Construir dimens√£o\n",
    "dim_loc_data = []\n",
    "for uf in sorted(ufs_unicas):\n",
    "    if uf in UFS_INFO:\n",
    "        info = UFS_INFO[uf]\n",
    "        dim_loc_data.append({\n",
    "            'sg_uf': uf,\n",
    "            'nm_uf': info[0],\n",
    "            'nm_regiao': info[1],\n",
    "            'cd_ibge': info[2],\n",
    "            'nm_capital': 'N/A'\n",
    "        })\n",
    "\n",
    "df_dim_loc = pd.DataFrame(dim_loc_data)\n",
    "print(f\"‚úÖ dim_loc: {len(df_dim_loc)} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11d7513",
   "metadata": {},
   "source": [
    "### 3.3 dim_pac (Dimens√£o Paciente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41935c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_pac: 123 perfis demogr√°ficos √∫nicos\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o para determinar faixa et√°ria detalhada\n",
    "def faixa_etaria_detalhada(idade):\n",
    "    if pd.isna(idade):\n",
    "        return 'UNKNOWN'\n",
    "    if idade < 1:\n",
    "        return 'Lactente'\n",
    "    elif idade < 12:\n",
    "        return 'Crian√ßa'\n",
    "    elif idade < 18:\n",
    "        return 'Adolescente'\n",
    "    elif idade < 60:\n",
    "        return 'Adulto'\n",
    "    else:\n",
    "        return 'Idoso'\n",
    "\n",
    "# Criar colunas auxiliares\n",
    "df_silver['ds_faixa_etaria'] = df_silver['faixa_etaria'].fillna('Nao informado')\n",
    "df_silver['ds_sexo'] = df_silver['sexo_desc'].fillna('UNKNOWN')\n",
    "df_silver['ds_raca'] = df_silver['raca_desc'].fillna('UNKNOWN')\n",
    "df_silver['ds_faixa_etaria_det'] = df_silver['idade_anos'].apply(faixa_etaria_detalhada)\n",
    "\n",
    "# Natural key para perfil demogr√°fico\n",
    "df_silver['nk_demografica'] = (df_silver['ds_faixa_etaria'] + '|' + \n",
    "                                df_silver['ds_sexo'] + '|' + \n",
    "                                df_silver['ds_raca'])\n",
    "\n",
    "# Criar dimens√£o com perfis √∫nicos (subset='nk_demografica' garante unicidade da NK)\n",
    "df_dim_pac = df_silver[['nk_demografica', 'ds_faixa_etaria', 'ds_sexo', 'ds_raca', 'ds_faixa_etaria_det']].drop_duplicates(subset=['nk_demografica'])\n",
    "print(f\"‚úÖ dim_pac: {len(df_dim_pac)} perfis demogr√°ficos √∫nicos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20724e25",
   "metadata": {},
   "source": [
    "### 3.4 dim_cls (Dimens√£o Classifica√ß√£o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee9fa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Classifica√ß√µes encontradas: ['Dengue' 'Inconclusivo' 'Dengue com Sinais de Alarme' 'Dengue Grave'\n",
      " 'Em investigacao']\n",
      "‚úÖ dim_cls: 5 tipos de classifica√ß√£o\n"
     ]
    }
   ],
   "source": [
    "# Mapeamento de classifica√ß√µes para informa√ß√µes adicionais\n",
    "CLASSIF_INFO = {\n",
    "    'Dengue': ('10', 'Confirmado', 'Leve', 'A90', True),\n",
    "    'Dengue com Sinais de Alarme': ('11', 'Confirmado', 'Moderado', 'A91', True),\n",
    "    'Dengue Grave': ('12', 'Confirmado', 'Grave', 'A91', True),\n",
    "    'Chikungunya': ('13', 'Confirmado', 'Vari√°vel', 'A92.0', True),\n",
    "    'Descartado': ('5', 'Negativo', 'N/A', None, False),\n",
    "    'Inconclusivo': ('8', 'Indeterminado', 'N/A', None, False),\n",
    "    'Em investigacao': ('0', 'Em Investiga√ß√£o', 'N/A', None, False)\n",
    "}\n",
    "\n",
    "# Extrair classifica√ß√µes √∫nicas dos dados\n",
    "classifs_unicas = df_silver['classificacao_desc'].dropna().unique()\n",
    "print(f\"üìã Classifica√ß√µes encontradas: {classifs_unicas}\")\n",
    "\n",
    "# Construir dimens√£o\n",
    "dim_cls_data = []\n",
    "for classif in sorted(classifs_unicas):\n",
    "    if classif in CLASSIF_INFO:\n",
    "        info = CLASSIF_INFO[classif]\n",
    "        dim_cls_data.append({\n",
    "            'cd_classificacao': info[0],\n",
    "            'ds_classificacao': classif,\n",
    "            'ds_grupo': info[1],\n",
    "            'ds_gravidade': info[2],\n",
    "            'cd_cid': info[3],\n",
    "            'flag_confirmado': info[4]\n",
    "        })\n",
    "    else:\n",
    "        # Classifica√ß√£o n√£o mapeada\n",
    "        dim_cls_data.append({\n",
    "            'cd_classificacao': '99',\n",
    "            'ds_classificacao': classif,\n",
    "            'ds_grupo': 'Outros',\n",
    "            'ds_gravidade': 'N/A',\n",
    "            'cd_cid': None,\n",
    "            'flag_confirmado': False\n",
    "        })\n",
    "\n",
    "df_dim_cls = pd.DataFrame(dim_cls_data)\n",
    "print(f\"‚úÖ dim_cls: {len(df_dim_cls)} tipos de classifica√ß√£o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fec001",
   "metadata": {},
   "source": [
    "### 3.5 dim_evl (Dimens√£o Evolu√ß√£o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c093972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Evolu√ß√µes encontradas: ['Cura' 'Em investigacao' 'Ignorado' 'Obito por outras causas'\n",
      " 'Obito pelo agravo' 'Obito em investigacao']\n",
      "‚úÖ dim_evl: 6 tipos de evolu√ß√£o\n"
     ]
    }
   ],
   "source": [
    "# Mapeamento de evolu√ß√µes para informa√ß√µes adicionais\n",
    "EVOL_INFO = {\n",
    "    'Cura': ('1', 'Favor√°vel', False, 'Baixa'),\n",
    "    'Obito pelo agravo': ('2', '√ìbito', True, 'Cr√≠tica'),\n",
    "    'Obito por outras causas': ('3', '√ìbito', True, 'Cr√≠tica'),\n",
    "    'Obito em investigacao': ('4', '√ìbito', True, 'Cr√≠tica'),\n",
    "    'Ignorado': ('9', 'Indeterminado', False, 'Indeterminada'),\n",
    "    'Em investigacao': ('0', 'Em Investiga√ß√£o', False, 'Indeterminada')\n",
    "}\n",
    "\n",
    "# Extrair evolu√ß√µes √∫nicas dos dados\n",
    "evolucoes_unicas = df_silver['evolucao_desc'].dropna().unique()\n",
    "print(f\"üìã Evolu√ß√µes encontradas: {evolucoes_unicas}\")\n",
    "\n",
    "# Construir dimens√£o\n",
    "dim_evl_data = []\n",
    "for evol in sorted(evolucoes_unicas):\n",
    "    if evol in EVOL_INFO:\n",
    "        info = EVOL_INFO[evol]\n",
    "        dim_evl_data.append({\n",
    "            'cd_evolucao': info[0],\n",
    "            'ds_evolucao': evol,\n",
    "            'ds_tipo_evolucao': info[1],\n",
    "            'flag_obito': info[2],\n",
    "            'ds_gravidade_desfecho': info[3]\n",
    "        })\n",
    "    else:\n",
    "        dim_evl_data.append({\n",
    "            'cd_evolucao': '99',\n",
    "            'ds_evolucao': evol,\n",
    "            'ds_tipo_evolucao': 'Outros',\n",
    "            'flag_obito': False,\n",
    "            'ds_gravidade_desfecho': 'Indeterminada'\n",
    "        })\n",
    "\n",
    "df_dim_evl = pd.DataFrame(dim_evl_data)\n",
    "print(f\"‚úÖ dim_evl: {len(df_dim_evl)} tipos de evolu√ß√£o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a47bce3",
   "metadata": {},
   "source": [
    "### 3.6 dim_snt (Dimens√£o Sintomas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b74cdf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_snt: 12 perfis de sintomas\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√µes para classificar faixas de sintomas e alarmes\n",
    "def faixa_sintomas(qtd):\n",
    "    if pd.isna(qtd) or qtd == 0:\n",
    "        return 'Nenhum'\n",
    "    elif qtd <= 2:\n",
    "        return 'Poucos (1-2)'\n",
    "    elif qtd <= 5:\n",
    "        return 'Moderado (3-5)'\n",
    "    else:\n",
    "        return 'Muitos (6+)'\n",
    "\n",
    "def faixa_alarmes(qtd):\n",
    "    if pd.isna(qtd) or qtd == 0:\n",
    "        return 'Nenhum'\n",
    "    elif qtd <= 2:\n",
    "        return 'Poucos (1-2)'\n",
    "    else:\n",
    "        return 'M√∫ltiplos (3+)'\n",
    "\n",
    "def perfil_clinico(sint, alarm):\n",
    "    if sint == 0 and alarm == 0:\n",
    "        return 'Assintom√°tico'\n",
    "    elif alarm == 0:\n",
    "        return 'Dengue Cl√°ssica'\n",
    "    elif alarm <= 2:\n",
    "        return 'Dengue com Alarme'\n",
    "    else:\n",
    "        return 'Dengue Grave'\n",
    "\n",
    "# Criar colunas auxiliares usando qtd_sintomas e qtd_alarmes j√° existentes\n",
    "df_silver['ds_faixa_sintomas'] = df_silver['qtd_sintomas'].apply(faixa_sintomas)\n",
    "df_silver['ds_faixa_alarmes'] = df_silver['qtd_alarmes'].apply(faixa_alarmes)\n",
    "df_silver['ds_perfil_clinico'] = df_silver.apply(lambda x: perfil_clinico(x['qtd_sintomas'], x['qtd_alarmes']), axis=1)\n",
    "df_silver['flag_tem_sintomas'] = df_silver['qtd_sintomas'] > 0\n",
    "df_silver['flag_tem_alarmes'] = df_silver['qtd_alarmes'] > 0\n",
    "\n",
    "# Natural key\n",
    "df_silver['nk_sintomas'] = df_silver['ds_faixa_sintomas'] + '|' + df_silver['ds_faixa_alarmes']\n",
    "\n",
    "# Criar dimens√£o com combina√ß√µes √∫nicas\n",
    "df_dim_snt = df_silver[['nk_sintomas', 'ds_faixa_sintomas', 'ds_faixa_alarmes', 'ds_perfil_clinico', \n",
    "                         'flag_tem_sintomas', 'flag_tem_alarmes']].drop_duplicates()\n",
    "print(f\"‚úÖ dim_snt: {len(df_dim_snt)} perfis de sintomas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9dbb3f",
   "metadata": {},
   "source": [
    "## 4. Carga das Dimens√µes no PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1be41ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Limpando tabelas existentes...\n",
      "‚úÖ Tabelas limpas!\n",
      "\n",
      "‚è≥ Carregando dimens√µes no banco de dados...\n",
      "   dim_tmp: 373 registros\n",
      "   dim_loc: 27 registros\n",
      "   dim_pac: 123 registros\n",
      "   dim_cls: 5 registros\n",
      "   dim_evl: 6 registros\n",
      "   dim_snt: 12 registros\n",
      "\n",
      "‚úÖ Todas as dimens√µes carregadas!\n"
     ]
    }
   ],
   "source": [
    "def load_dimension(df, table_name, columns):\n",
    "    \"\"\"Carrega uma dimens√£o no banco de dados\"\"\"\n",
    "    placeholders = ','.join(['%s'] * len(columns))\n",
    "    sql = f\"INSERT INTO {table_name} ({','.join(columns)}) VALUES ({placeholders})\"\n",
    "    \n",
    "    data = []\n",
    "    for _, row in df.iterrows():\n",
    "        record = tuple(row[col] if pd.notna(row[col]) else None for col in columns)\n",
    "        data.append(record)\n",
    "    \n",
    "    cursor.executemany(sql, data)\n",
    "    conn.commit()\n",
    "    return len(data)\n",
    "\n",
    "# Rollback de qualquer transa√ß√£o pendente (em caso de erro anterior)\n",
    "conn.rollback()\n",
    "\n",
    "print(\"‚è≥ Limpando tabelas existentes...\")\n",
    "\n",
    "# TRUNCATE com RESTART IDENTITY para resetar as sequences\n",
    "cursor.execute(\"TRUNCATE TABLE gold.ft_deng RESTART IDENTITY CASCADE\")\n",
    "conn.commit()\n",
    "cursor.execute(\"TRUNCATE TABLE gold.dim_tmp RESTART IDENTITY CASCADE\")\n",
    "conn.commit()\n",
    "cursor.execute(\"TRUNCATE TABLE gold.dim_loc RESTART IDENTITY CASCADE\")\n",
    "conn.commit()\n",
    "cursor.execute(\"TRUNCATE TABLE gold.dim_pac RESTART IDENTITY CASCADE\")\n",
    "conn.commit()\n",
    "cursor.execute(\"TRUNCATE TABLE gold.dim_cls RESTART IDENTITY CASCADE\")\n",
    "conn.commit()\n",
    "cursor.execute(\"TRUNCATE TABLE gold.dim_evl RESTART IDENTITY CASCADE\")\n",
    "conn.commit()\n",
    "cursor.execute(\"TRUNCATE TABLE gold.dim_snt RESTART IDENTITY CASCADE\")\n",
    "conn.commit()\n",
    "print(\"‚úÖ Tabelas limpas!\")\n",
    "\n",
    "print(\"\\n‚è≥ Carregando dimens√µes no banco de dados...\")\n",
    "\n",
    "# dim_tmp\n",
    "n = load_dimension(df_dim_tempo, 'gold.dim_tmp', \n",
    "    ['dt_completa', 'nr_ano', 'nr_mes', 'nr_dia', 'nr_trimestre', 'nr_semana_epi', \n",
    "     'nr_dia_semana', 'nm_dia', 'flag_fim_semana', 'ds_mes_ano', 'ds_ano_trimestre'])\n",
    "print(f\"   dim_tmp: {n} registros\")\n",
    "\n",
    "# dim_loc\n",
    "n = load_dimension(df_dim_loc, 'gold.dim_loc', \n",
    "    ['sg_uf', 'nm_uf', 'nm_regiao', 'cd_ibge', 'nm_capital'])\n",
    "print(f\"   dim_loc: {n} registros\")\n",
    "\n",
    "# dim_pac\n",
    "n = load_dimension(df_dim_pac, 'gold.dim_pac', \n",
    "    ['nk_demografica', 'ds_faixa_etaria', 'ds_sexo', 'ds_raca', 'ds_faixa_etaria_det'])\n",
    "print(f\"   dim_pac: {n} registros\")\n",
    "\n",
    "# dim_cls\n",
    "n = load_dimension(df_dim_cls, 'gold.dim_cls', \n",
    "    ['cd_classificacao', 'ds_classificacao', 'ds_grupo', 'ds_gravidade', 'cd_cid', 'flag_confirmado'])\n",
    "print(f\"   dim_cls: {n} registros\")\n",
    "\n",
    "# dim_evl\n",
    "n = load_dimension(df_dim_evl, 'gold.dim_evl', \n",
    "    ['cd_evolucao', 'ds_evolucao', 'ds_tipo_evolucao', 'flag_obito', 'ds_gravidade_desfecho'])\n",
    "print(f\"   dim_evl: {n} registros\")\n",
    "\n",
    "# dim_snt\n",
    "n = load_dimension(df_dim_snt, 'gold.dim_snt', \n",
    "    ['nk_sintomas', 'ds_faixa_sintomas', 'ds_faixa_alarmes', 'ds_perfil_clinico', 'flag_tem_sintomas', 'flag_tem_alarmes'])\n",
    "print(f\"   dim_snt: {n} registros\")\n",
    "\n",
    "print(\"\\n‚úÖ Todas as dimens√µes carregadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5f3c7",
   "metadata": {},
   "source": [
    "## 5. Criar Lookups para Tabela Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "914a9e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Criando lookups das dimens√µes...\n",
      "‚úÖ Lookups criados:\n",
      "   dim_tmp: 373 datas\n",
      "   dim_loc: 27 UFs\n",
      "   dim_pac: 123 perfis\n",
      "   dim_cls: 5 classifica√ß√µes\n",
      "   dim_evl: 6 evolu√ß√µes\n",
      "   dim_snt: 12 sintomas\n"
     ]
    }
   ],
   "source": [
    "print(\"‚è≥ Criando lookups das dimens√µes...\")\n",
    "\n",
    "# Lookup dim_tmp (data -> sk_tmp)\n",
    "cursor.execute(\"SELECT sk_tmp, dt_completa FROM gold.dim_tmp\")\n",
    "lk_tmp = {row[1]: row[0] for row in cursor.fetchall()}\n",
    "\n",
    "# Lookup dim_loc (uf_sigla -> sk_loc)\n",
    "cursor.execute(\"SELECT sk_loc, sg_uf FROM gold.dim_loc\")\n",
    "lk_loc = {row[1]: row[0] for row in cursor.fetchall()}\n",
    "\n",
    "# Lookup dim_pac (nk_demografica -> sk_pac)\n",
    "cursor.execute(\"SELECT sk_pac, nk_demografica FROM gold.dim_pac\")\n",
    "lk_pac = {row[1]: row[0] for row in cursor.fetchall()}\n",
    "\n",
    "# Lookup dim_cls (ds_classificacao -> sk_cls)\n",
    "cursor.execute(\"SELECT sk_cls, ds_classificacao FROM gold.dim_cls\")\n",
    "lk_cls = {row[1]: row[0] for row in cursor.fetchall()}\n",
    "\n",
    "# Lookup dim_evl (ds_evolucao -> sk_evl)\n",
    "cursor.execute(\"SELECT sk_evl, ds_evolucao FROM gold.dim_evl\")\n",
    "lk_evl = {row[1]: row[0] for row in cursor.fetchall()}\n",
    "\n",
    "# Lookup dim_snt (nk_sintomas -> sk_snt)\n",
    "cursor.execute(\"SELECT sk_snt, nk_sintomas FROM gold.dim_snt\")\n",
    "lk_snt = {row[1]: row[0] for row in cursor.fetchall()}\n",
    "\n",
    "print(f\"‚úÖ Lookups criados:\")\n",
    "print(f\"   dim_tmp: {len(lk_tmp)} datas\")\n",
    "print(f\"   dim_loc: {len(lk_loc)} UFs\")\n",
    "print(f\"   dim_pac: {len(lk_pac)} perfis\")\n",
    "print(f\"   dim_cls: {len(lk_cls)} classifica√ß√µes\")\n",
    "print(f\"   dim_evl: {len(lk_evl)} evolu√ß√µes\")\n",
    "print(f\"   dim_snt: {len(lk_snt)} sintomas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3c624e",
   "metadata": {},
   "source": [
    "## 6. Preparar e Carregar Tabela Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d64b99f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Preparando tabela fato...\n",
      "‚úÖ Tabela fato preparada: 1,661,634 registros\n"
     ]
    }
   ],
   "source": [
    "print(\"‚è≥ Preparando tabela fato...\")\n",
    "\n",
    "# Preparar DataFrame da fato\n",
    "df_fato = pd.DataFrame()\n",
    "\n",
    "# Natural key\n",
    "df_fato['nk_notificacao'] = df_silver['id_notificacao']\n",
    "\n",
    "# Foreign keys (usando lookups)\n",
    "df_fato['fk_tmp'] = df_silver['data_notificacao'].apply(\n",
    "    lambda x: lk_tmp.get(x, -1) if pd.notna(x) else -1\n",
    ")\n",
    "\n",
    "df_fato['fk_loc'] = df_silver['uf_sigla'].apply(\n",
    "    lambda x: lk_loc.get(x, -1) if pd.notna(x) else -1\n",
    ")\n",
    "\n",
    "df_fato['fk_pac'] = df_silver['nk_demografica'].apply(\n",
    "    lambda x: lk_pac.get(x, -1) if pd.notna(x) else -1\n",
    ")\n",
    "\n",
    "df_fato['fk_cls'] = df_silver['classificacao_desc'].apply(\n",
    "    lambda x: lk_cls.get(x, -1) if pd.notna(x) else -1\n",
    ")\n",
    "\n",
    "df_fato['fk_evl'] = df_silver['evolucao_desc'].apply(\n",
    "    lambda x: lk_evl.get(x, -1) if pd.notna(x) else -1\n",
    ")\n",
    "\n",
    "df_fato['fk_snt'] = df_silver['nk_sintomas'].apply(\n",
    "    lambda x: lk_snt.get(x, -1) if pd.notna(x) else -1\n",
    ")\n",
    "\n",
    "# M√©tricas (j√° calculadas na Silver Layer)\n",
    "df_fato['vl_confirmado'] = df_silver['fl_confirmado'].fillna(0).astype(int)\n",
    "df_fato['vl_grave'] = df_silver['fl_grave'].fillna(0).astype(int)\n",
    "df_fato['vl_obito'] = df_silver['fl_obito'].fillna(0).astype(int)\n",
    "df_fato['vl_hospitalizado'] = df_silver['fl_hospitalizado'].fillna(0).astype(int)\n",
    "df_fato['vl_qtd_sintomas'] = df_silver['qtd_sintomas'].fillna(0).astype(int)\n",
    "df_fato['vl_qtd_alarmes'] = df_silver['qtd_alarmes'].fillna(0).astype(int)\n",
    "df_fato['vl_idade_anos'] = df_silver['idade_anos']\n",
    "\n",
    "# Datas\n",
    "df_fato['dt_notificacao'] = df_silver['data_notificacao']\n",
    "df_fato['dt_sintomas'] = df_silver['data_sintomas']\n",
    "\n",
    "print(f\"‚úÖ Tabela fato preparada: {len(df_fato):,} registros\")\n",
    "\n",
    "# Verificar FKs inv√°lidas\n",
    "for col in ['fk_tmp', 'fk_loc', 'fk_pac', 'fk_cls', 'fk_evl', 'fk_snt']:\n",
    "    invalidas = (df_fato[col] == -1).sum()\n",
    "    if invalidas > 0:\n",
    "        print(f\"   ‚ö†Ô∏è {col}: {invalidas:,} FKs inv√°lidas ({invalidas/len(df_fato)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a265ecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Carregando 1,661,634 registros em 34 batches...\n",
      "   Batch 1/34: 50,000 registros (3%)\n"
     ]
    }
   ],
   "source": [
    "# Carga da tabela fato em batches\n",
    "cols = ['nk_notificacao', 'fk_tmp', 'fk_loc', 'fk_pac', 'fk_cls', 'fk_evl', 'fk_snt',\n",
    "        'vl_confirmado', 'vl_grave', 'vl_obito', 'vl_hospitalizado', \n",
    "        'vl_qtd_sintomas', 'vl_qtd_alarmes', 'vl_idade_anos',\n",
    "        'dt_notificacao', 'dt_sintomas']\n",
    "\n",
    "sql = f\"INSERT INTO gold.ft_deng ({','.join(cols)}) VALUES %s\"\n",
    "\n",
    "total = len(df_fato)\n",
    "batches = (total + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "print(f\"‚è≥ Carregando {total:,} registros em {batches} batches...\")\n",
    "\n",
    "for i in range(batches):\n",
    "    start = i * BATCH_SIZE\n",
    "    end = min((i + 1) * BATCH_SIZE, total)\n",
    "    batch = df_fato.iloc[start:end]\n",
    "    \n",
    "    data = []\n",
    "    for _, row in batch.iterrows():\n",
    "        record = tuple(row[c] if pd.notna(row[c]) else None for c in cols)\n",
    "        data.append(record)\n",
    "    \n",
    "    execute_values(cursor, sql, data)\n",
    "    conn.commit()\n",
    "    \n",
    "    pct = (i + 1) / batches * 100\n",
    "    print(f\"   Batch {i+1}/{batches}: {end:,} registros ({pct:.0f}%)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Carga conclu√≠da: {total:,} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e148e56",
   "metadata": {},
   "source": [
    "## 7. Valida√ß√£o Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a30ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç VALIDA√á√ÉO FINAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Contagem Gold\n",
    "cursor.execute(\"SELECT COUNT(*) FROM gold.ft_deng\")\n",
    "total_gold = cursor.fetchone()[0]\n",
    "\n",
    "print(f\"\\nüìä VOLUMETRIA:\")\n",
    "print(f\"   Silver (public.dengue_silver): {total_silver:,}\")\n",
    "print(f\"   Gold (gold.ft_deng): {total_gold:,}\")\n",
    "print(f\"   Status: {'‚úÖ OK - Volumes iguais' if total_gold == total_silver else '‚ùå DIFEREN√áA'}\")\n",
    "\n",
    "# M√©tricas\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT \n",
    "        SUM(vl_confirmado) as confirmados,\n",
    "        SUM(vl_grave) as graves,\n",
    "        SUM(vl_obito) as obitos,\n",
    "        SUM(vl_hospitalizado) as hospitalizados\n",
    "    FROM gold.ft_deng\n",
    "\"\"\")\n",
    "metricas = cursor.fetchone()\n",
    "\n",
    "print(f\"\\nüìà M√âTRICAS EPIDEMIOL√ìGICAS:\")\n",
    "print(f\"   Casos confirmados: {metricas[0]:,}\")\n",
    "print(f\"   Casos graves: {metricas[1]:,}\")\n",
    "print(f\"   √ìbitos: {metricas[2]:,}\")\n",
    "print(f\"   Hospitaliza√ß√µes: {metricas[3]:,}\")\n",
    "\n",
    "if metricas[0] > 0:\n",
    "    taxa_letalidade = metricas[2] / metricas[0] * 100\n",
    "    taxa_gravidade = metricas[1] / metricas[0] * 100\n",
    "    print(f\"\\n   Taxa de letalidade: {taxa_letalidade:.4f}%\")\n",
    "    print(f\"   Taxa de gravidade: {taxa_gravidade:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c4421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valida√ß√£o das dimens√µes\n",
    "print(\"\\nüìã DIMENS√ïES:\")\n",
    "dimensoes = ['dim_tmp', 'dim_loc', 'dim_pac', 'dim_cls', 'dim_evl', 'dim_snt']\n",
    "for dim in dimensoes:\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM gold.{dim}\")\n",
    "    count = cursor.fetchone()[0]\n",
    "    print(f\"   {dim}: {count} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db011071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 UFs por casos\n",
    "print(\"\\nüèÜ TOP 5 UFs POR CASOS CONFIRMADOS:\")\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT l.sg_uf, l.nm_uf, l.nm_regiao,\n",
    "           SUM(f.vl_confirmado) as casos,\n",
    "           SUM(f.vl_obito) as obitos\n",
    "    FROM gold.ft_deng f\n",
    "    JOIN gold.dim_loc l ON f.fk_loc = l.sk_loc\n",
    "    GROUP BY l.sg_uf, l.nm_uf, l.nm_regiao\n",
    "    ORDER BY casos DESC\n",
    "    LIMIT 5\n",
    "\"\"\")\n",
    "for row in cursor.fetchall():\n",
    "    print(f\"   {row[0]} ({row[1]}/{row[2]}): {row[3]:,} casos, {row[4]:,} √≥bitos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be430596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fechar conex√£o\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ ETL SILVER ‚Üí GOLD CONCLU√çDO COM SUCESSO!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
