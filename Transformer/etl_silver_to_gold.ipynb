{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ETL Silver -> Gold Layer\n",
    "## Data Warehouse Dengue 2025 - Star Schema\n",
    "### Padrao: Nomenclatura corporativa 3 letras UPPERCASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup concluido\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from datetime import datetime, date\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'database': 'gis',\n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres'\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 50_000\n",
    "print(\"Setup concluido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1",
   "metadata": {},
   "source": [
    "## 1. Conexao e Verificacao Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "connect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver Layer - Resumo:\n",
      "   Total: 1,661,634\n",
      "   Periodo: 2024-12-29 a 2026-01-05\n",
      "   UFs: 27\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT COUNT(*) as total,\n",
    "           MIN(data_notificacao) as data_min,\n",
    "           MAX(data_notificacao) as data_max,\n",
    "           COUNT(DISTINCT uf_sigla) as qtd_ufs\n",
    "    FROM silver.dengue_silver\n",
    "\"\"\")\n",
    "result = cursor.fetchone()\n",
    "total_silver = result[0]\n",
    "\n",
    "print(\"Silver Layer - Resumo:\")\n",
    "print(f\"   Total: {total_silver:,}\")\n",
    "print(f\"   Periodo: {result[1]} a {result[2]}\")\n",
    "print(f\"   UFs: {result[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2",
   "metadata": {},
   "source": [
    "## 2. Carregar Dados Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "load_silver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados...\n",
      "Carregados 1,661,634 registros\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    id_notificacao, uf_sigla, data_notificacao, data_sintomas,\n",
    "    idade_anos, faixa_etaria, sexo_desc, raca_desc,\n",
    "    qtd_sintomas, qtd_alarmes, classificacao_desc, evolucao_desc,\n",
    "    fl_confirmado, fl_grave, fl_obito, fl_hospitalizado\n",
    "FROM silver.dengue_silver\n",
    "\"\"\"\n",
    "\n",
    "print(\"Carregando dados...\")\n",
    "df_silver = pd.read_sql(query, conn)\n",
    "print(f\"Carregados {len(df_silver):,} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3",
   "metadata": {},
   "source": [
    "## 3. Construcao das Dimensoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dim_tmp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIM_TMP: 373 registros\n"
     ]
    }
   ],
   "source": [
    "# DIM_TMP - Dimensao Tempo\n",
    "DIAS_SEMANA = {0: 'Segunda', 1: 'Terca', 2: 'Quarta', 3: 'Quinta', 4: 'Sexta', 5: 'Sabado', 6: 'Domingo'}\n",
    "\n",
    "datas_notif = pd.to_datetime(df_silver['data_notificacao'].dropna().unique())\n",
    "datas_sint = pd.to_datetime(df_silver['data_sintomas'].dropna().unique())\n",
    "datas_unicas = pd.Series(list(set(datas_notif) | set(datas_sint))).dropna().unique()\n",
    "\n",
    "dim_tempo_data = []\n",
    "for i, d in enumerate(sorted(pd.to_datetime(datas_unicas))):\n",
    "    dim_tempo_data.append({\n",
    "        'TMP_SRK': i + 1,\n",
    "        'DAT_COM': d.date(),\n",
    "        'NUM_ANO': d.year,\n",
    "        'NUM_MES': d.month,\n",
    "        'NUM_DIA': d.day,\n",
    "        'NUM_TRI': (d.month - 1) // 3 + 1,\n",
    "        'NUM_SEM_EPI': d.isocalendar()[1],\n",
    "        'NUM_DIA_SEM': d.dayofweek + 1,\n",
    "        'NOM_DIA': DIAS_SEMANA[d.dayofweek],\n",
    "        'IND_FDS': 1 if d.dayofweek >= 5 else 0,\n",
    "        'DES_MES_ANO': f\"{d.year}-{d.month:02d}\",\n",
    "        'DES_ANO_TRI': f\"{d.year}-Q{(d.month - 1) // 3 + 1}\"\n",
    "    })\n",
    "\n",
    "df_dim_tempo = pd.DataFrame(dim_tempo_data)\n",
    "print(f\"DIM_TMP: {len(df_dim_tempo)} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dim_loc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIM_LOC: 27 registros\n"
     ]
    }
   ],
   "source": [
    "# DIM_LOC - Dimensao Localizacao\n",
    "UFS_INFO = {\n",
    "    'AC': ('Acre', 'Norte', 12), 'AL': ('Alagoas', 'Nordeste', 27), 'AP': ('Amapa', 'Norte', 16),\n",
    "    'AM': ('Amazonas', 'Norte', 13), 'BA': ('Bahia', 'Nordeste', 29), 'CE': ('Ceara', 'Nordeste', 23),\n",
    "    'DF': ('Distrito Federal', 'Centro-Oeste', 53), 'ES': ('Espirito Santo', 'Sudeste', 32),\n",
    "    'GO': ('Goias', 'Centro-Oeste', 52), 'MA': ('Maranhao', 'Nordeste', 21), 'MT': ('Mato Grosso', 'Centro-Oeste', 51),\n",
    "    'MS': ('Mato Grosso do Sul', 'Centro-Oeste', 50), 'MG': ('Minas Gerais', 'Sudeste', 31),\n",
    "    'PA': ('Para', 'Norte', 15), 'PB': ('Paraiba', 'Nordeste', 25), 'PR': ('Parana', 'Sul', 41),\n",
    "    'PE': ('Pernambuco', 'Nordeste', 26), 'PI': ('Piaui', 'Nordeste', 22), 'RJ': ('Rio de Janeiro', 'Sudeste', 33),\n",
    "    'RN': ('Rio Grande do Norte', 'Nordeste', 24), 'RS': ('Rio Grande do Sul', 'Sul', 43),\n",
    "    'RO': ('Rondonia', 'Norte', 11), 'RR': ('Roraima', 'Norte', 14), 'SC': ('Santa Catarina', 'Sul', 42),\n",
    "    'SP': ('Sao Paulo', 'Sudeste', 35), 'SE': ('Sergipe', 'Nordeste', 28), 'TO': ('Tocantins', 'Norte', 17)\n",
    "}\n",
    "\n",
    "ufs_unicas = df_silver['uf_sigla'].dropna().unique()\n",
    "dim_loc_data = []\n",
    "for i, uf in enumerate(sorted(ufs_unicas)):\n",
    "    if uf in UFS_INFO:\n",
    "        info = UFS_INFO[uf]\n",
    "        dim_loc_data.append({\n",
    "            'LOC_SRK': i + 1, 'SIG_UNF': uf, 'NOM_UNF': info[0],\n",
    "            'NOM_REG': info[1], 'COD_IBG': info[2], 'NOM_CAP': 'N/A'\n",
    "        })\n",
    "\n",
    "df_dim_loc = pd.DataFrame(dim_loc_data)\n",
    "print(f\"DIM_LOC: {len(df_dim_loc)} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dim_pac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIM_PAC: 123 registros\n"
     ]
    }
   ],
   "source": [
    "# DIM_PAC - Dimensao Paciente\n",
    "def faixa_etaria_det(idade):\n",
    "    if pd.isna(idade): return 'UNKNOWN'\n",
    "    if idade < 1: return 'Lactente'\n",
    "    elif idade < 12: return 'Crianca'\n",
    "    elif idade < 18: return 'Adolescente'\n",
    "    elif idade < 60: return 'Adulto'\n",
    "    else: return 'Idoso'\n",
    "\n",
    "df_silver['DES_FAI_ETA'] = df_silver['faixa_etaria'].fillna('Nao informado')\n",
    "df_silver['DES_SEX'] = df_silver['sexo_desc'].fillna('UNKNOWN')\n",
    "df_silver['DES_RAC'] = df_silver['raca_desc'].fillna('UNKNOWN')\n",
    "df_silver['DES_FAI_ETA_DET'] = df_silver['idade_anos'].apply(faixa_etaria_det)\n",
    "df_silver['COD_DEM'] = df_silver['DES_FAI_ETA'] + '|' + df_silver['DES_SEX'] + '|' + df_silver['DES_RAC']\n",
    "\n",
    "df_dim_pac_temp = df_silver[['COD_DEM', 'DES_FAI_ETA', 'DES_SEX', 'DES_RAC', 'DES_FAI_ETA_DET']].drop_duplicates(subset=['COD_DEM']).reset_index(drop=True)\n",
    "df_dim_pac_temp['PAC_SRK'] = df_dim_pac_temp.index + 1\n",
    "df_dim_pac = df_dim_pac_temp[['PAC_SRK', 'COD_DEM', 'DES_FAI_ETA', 'DES_SEX', 'DES_RAC', 'DES_FAI_ETA_DET']]\n",
    "print(f\"DIM_PAC: {len(df_dim_pac)} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dim_cls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIM_CLS: 5 registros\n"
     ]
    }
   ],
   "source": [
    "# DIM_CLS - Dimensao Classificacao\n",
    "CLASSIF_INFO = {\n",
    "    'Dengue': ('10', 'Confirmado', 'Leve', 'A90', 1),\n",
    "    'Dengue com Sinais de Alarme': ('11', 'Confirmado', 'Moderado', 'A91', 1),\n",
    "    'Dengue Grave': ('12', 'Confirmado', 'Grave', 'A91', 1),\n",
    "    'Inconclusivo': ('8', 'Indeterminado', 'N/A', None, 0),\n",
    "    'Em investigacao': ('0', 'Em Investigacao', 'N/A', None, 0)\n",
    "}\n",
    "\n",
    "classifs = df_silver['classificacao_desc'].dropna().unique()\n",
    "dim_cls_data = []\n",
    "for i, c in enumerate(sorted(classifs)):\n",
    "    info = CLASSIF_INFO.get(c, ('99', 'Outros', 'N/A', None, 0))\n",
    "    dim_cls_data.append({'CLS_SRK': i+1, 'COD_CLS': info[0], 'DES_CLS': c, 'DES_GRP': info[1], 'DES_GRA': info[2], 'COD_CID': info[3], 'IND_CON': info[4]})\n",
    "\n",
    "df_dim_cls = pd.DataFrame(dim_cls_data)\n",
    "print(f\"DIM_CLS: {len(df_dim_cls)} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dim_evl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIM_EVL: 6 registros\n"
     ]
    }
   ],
   "source": [
    "# DIM_EVL - Dimensao Evolucao\n",
    "EVOL_INFO = {\n",
    "    'Cura': ('1', 'Favoravel', 0, 'Baixa'),\n",
    "    'Obito pelo agravo': ('2', 'Obito', 1, 'Critica'),\n",
    "    'Obito por outras causas': ('3', 'Obito', 1, 'Critica'),\n",
    "    'Obito em investigacao': ('4', 'Obito', 1, 'Critica'),\n",
    "    'Ignorado': ('9', 'Indeterminado', 0, 'Indeterminada'),\n",
    "    'Em investigacao': ('0', 'Em Investigacao', 0, 'Indeterminada')\n",
    "}\n",
    "\n",
    "evols = df_silver['evolucao_desc'].dropna().unique()\n",
    "dim_evl_data = []\n",
    "for i, e in enumerate(sorted(evols)):\n",
    "    info = EVOL_INFO.get(e, ('99', 'Outros', 0, 'Indeterminada'))\n",
    "    dim_evl_data.append({'EVL_SRK': i+1, 'COD_EVL': info[0], 'DES_EVL': e, 'TIP_EVL': info[1], 'IND_OBI': info[2], 'DES_GRA_DES': info[3]})\n",
    "\n",
    "df_dim_evl = pd.DataFrame(dim_evl_data)\n",
    "print(f\"DIM_EVL: {len(df_dim_evl)} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dim_snt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIM_SNT: 12 registros\n"
     ]
    }
   ],
   "source": [
    "# DIM_SNT - Dimensao Sintomas\n",
    "def fx_sint(q): return 'Nenhum' if pd.isna(q) or q==0 else 'Poucos (1-2)' if q<=2 else 'Moderado (3-5)' if q<=5 else 'Muitos (6+)'\n",
    "def fx_alr(q): return 'Nenhum' if pd.isna(q) or q==0 else 'Poucos (1-2)' if q<=2 else 'Multiplos (3+)'\n",
    "def perf_cli(s,a): return 'Assintomatico' if s==0 and a==0 else 'Dengue Classica' if a==0 else 'Dengue com Alarme' if a<=2 else 'Dengue Grave'\n",
    "\n",
    "df_silver['DES_FAI_SNT'] = df_silver['qtd_sintomas'].apply(fx_sint)\n",
    "df_silver['DES_FAI_ALR'] = df_silver['qtd_alarmes'].apply(fx_alr)\n",
    "df_silver['DES_PER_CLI'] = df_silver.apply(lambda x: perf_cli(x['qtd_sintomas'], x['qtd_alarmes']), axis=1)\n",
    "df_silver['IND_SNT'] = (df_silver['qtd_sintomas'] > 0).astype(int)\n",
    "df_silver['IND_ALR'] = (df_silver['qtd_alarmes'] > 0).astype(int)\n",
    "df_silver['COD_SNT'] = df_silver['DES_FAI_SNT'] + '|' + df_silver['DES_FAI_ALR']\n",
    "\n",
    "df_dim_snt_temp = df_silver[['COD_SNT', 'DES_FAI_SNT', 'DES_FAI_ALR', 'DES_PER_CLI', 'IND_SNT', 'IND_ALR']].drop_duplicates().reset_index(drop=True)\n",
    "df_dim_snt_temp['SNT_SRK'] = df_dim_snt_temp.index + 1\n",
    "df_dim_snt = df_dim_snt_temp[['SNT_SRK', 'COD_SNT', 'DES_FAI_SNT', 'DES_FAI_ALR', 'DES_PER_CLI', 'IND_SNT', 'IND_ALR']]\n",
    "print(f\"DIM_SNT: {len(df_dim_snt)} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4",
   "metadata": {},
   "source": [
    "## 4. Criar Schema Gold e Tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "create_schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema dw ja existe\n"
     ]
    }
   ],
   "source": [
    "# PASSO 1: Criar schema se nao existir\n",
    "conn.rollback()\n",
    "\n",
    "cursor.execute(\"SELECT schema_name FROM information_schema.schemata WHERE schema_name = 'dw'\")\n",
    "if cursor.fetchone() is None:\n",
    "    print(\"Criando schema dw...\")\n",
    "    cursor.execute(\"CREATE SCHEMA dw\")\n",
    "    conn.commit()\n",
    "    print(\"Schema dw criado!\")\n",
    "else:\n",
    "    print(\"Schema dw ja existe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "create_tables",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recriando tabelas...\n",
      "   DIM_TMP criada\n",
      "   DIM_LOC criada\n",
      "   DIM_PAC criada\n",
      "   DIM_CLS criada\n",
      "   DIM_EVL criada\n",
      "   DIM_SNT criada\n",
      "   FAT_DEN criada\n",
      "\n",
      "Tabelas criadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# PASSO 2: Dropar tabelas existentes e recriar\n",
    "print(\"Recriando tabelas...\")\n",
    "\n",
    "# Drop todas as tabelas (fato primeiro por causa das FKs)\n",
    "for t in ['FAT_DEN', 'DIM_TMP', 'DIM_LOC', 'DIM_PAC', 'DIM_CLS', 'DIM_EVL', 'DIM_SNT']:\n",
    "    cursor.execute(f\"DROP TABLE IF EXISTS dw.{t} CASCADE\")\n",
    "conn.commit()\n",
    "\n",
    "# Criar DIM_TMP\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE dw.DIM_TMP (\n",
    "        TMP_SRK BIGINT PRIMARY KEY,\n",
    "        DAT_COM DATE NOT NULL UNIQUE,\n",
    "        NUM_ANO INTEGER NOT NULL,\n",
    "        NUM_MES INTEGER NOT NULL,\n",
    "        NUM_DIA INTEGER NOT NULL,\n",
    "        NUM_TRI INTEGER NOT NULL,\n",
    "        NUM_SEM_EPI INTEGER NOT NULL,\n",
    "        NUM_DIA_SEM INTEGER NOT NULL,\n",
    "        NOM_DIA VARCHAR(20) NOT NULL,\n",
    "        IND_FDS INTEGER NOT NULL,\n",
    "        DES_MES_ANO VARCHAR(10) NOT NULL,\n",
    "        DES_ANO_TRI VARCHAR(10) NOT NULL\n",
    "    )\n",
    "\"\"\")\n",
    "print(\"   DIM_TMP criada\")\n",
    "\n",
    "# Criar DIM_LOC\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE dw.DIM_LOC (\n",
    "        LOC_SRK BIGINT PRIMARY KEY,\n",
    "        SIG_UNF CHAR(2) NOT NULL UNIQUE,\n",
    "        NOM_UNF VARCHAR(50) NOT NULL,\n",
    "        NOM_REG VARCHAR(20) NOT NULL,\n",
    "        COD_IBG INTEGER,\n",
    "        NOM_CAP VARCHAR(50)\n",
    "    )\n",
    "\"\"\")\n",
    "print(\"   DIM_LOC criada\")\n",
    "\n",
    "# Criar DIM_PAC\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE dw.DIM_PAC (\n",
    "        PAC_SRK BIGINT PRIMARY KEY,\n",
    "        COD_DEM VARCHAR(100) NOT NULL UNIQUE,\n",
    "        DES_FAI_ETA VARCHAR(30) NOT NULL,\n",
    "        DES_SEX VARCHAR(20) NOT NULL,\n",
    "        DES_RAC VARCHAR(30) NOT NULL,\n",
    "        DES_FAI_ETA_DET VARCHAR(50) NOT NULL\n",
    "    )\n",
    "\"\"\")\n",
    "print(\"   DIM_PAC criada\")\n",
    "\n",
    "# Criar DIM_CLS\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE dw.DIM_CLS (\n",
    "        CLS_SRK BIGINT PRIMARY KEY,\n",
    "        COD_CLS VARCHAR(10) NOT NULL,\n",
    "        DES_CLS VARCHAR(50) NOT NULL UNIQUE,\n",
    "        DES_GRP VARCHAR(30) NOT NULL,\n",
    "        DES_GRA VARCHAR(20) NOT NULL,\n",
    "        COD_CID VARCHAR(10),\n",
    "        IND_CON INTEGER NOT NULL\n",
    "    )\n",
    "\"\"\")\n",
    "print(\"   DIM_CLS criada\")\n",
    "\n",
    "# Criar DIM_EVL\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE dw.DIM_EVL (\n",
    "        EVL_SRK BIGINT PRIMARY KEY,\n",
    "        COD_EVL VARCHAR(10) NOT NULL,\n",
    "        DES_EVL VARCHAR(50) NOT NULL UNIQUE,\n",
    "        TIP_EVL VARCHAR(30) NOT NULL,\n",
    "        IND_OBI INTEGER NOT NULL,\n",
    "        DES_GRA_DES VARCHAR(30) NOT NULL\n",
    "    )\n",
    "\"\"\")\n",
    "print(\"   DIM_EVL criada\")\n",
    "\n",
    "# Criar DIM_SNT\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE dw.DIM_SNT (\n",
    "        SNT_SRK BIGINT PRIMARY KEY,\n",
    "        COD_SNT VARCHAR(50) NOT NULL UNIQUE,\n",
    "        DES_FAI_SNT VARCHAR(20) NOT NULL,\n",
    "        DES_FAI_ALR VARCHAR(20) NOT NULL,\n",
    "        DES_PER_CLI VARCHAR(30) NOT NULL,\n",
    "        IND_SNT INTEGER NOT NULL,\n",
    "        IND_ALR INTEGER NOT NULL\n",
    "    )\n",
    "\"\"\")\n",
    "print(\"   DIM_SNT criada\")\n",
    "\n",
    "# Criar FAT_DEN\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE dw.FAT_DEN (\n",
    "        FAT_SRK BIGINT PRIMARY KEY,\n",
    "        NUM_NOT BIGINT NOT NULL,\n",
    "        TMP_SRK BIGINT NOT NULL REFERENCES dw.DIM_TMP(TMP_SRK),\n",
    "        LOC_SRK BIGINT NOT NULL REFERENCES dw.DIM_LOC(LOC_SRK),\n",
    "        PAC_SRK BIGINT NOT NULL REFERENCES dw.DIM_PAC(PAC_SRK),\n",
    "        CLS_SRK BIGINT NOT NULL REFERENCES dw.DIM_CLS(CLS_SRK),\n",
    "        EVL_SRK BIGINT NOT NULL REFERENCES dw.DIM_EVL(EVL_SRK),\n",
    "        SNT_SRK BIGINT NOT NULL REFERENCES dw.DIM_SNT(SNT_SRK),\n",
    "        VAL_CON INTEGER NOT NULL,\n",
    "        VAL_GRA INTEGER NOT NULL,\n",
    "        VAL_OBI INTEGER NOT NULL,\n",
    "        VAL_HOS INTEGER NOT NULL,\n",
    "        QTD_SNT INTEGER NOT NULL,\n",
    "        QTD_ALR INTEGER NOT NULL,\n",
    "        VAL_IDA NUMERIC(5,2),\n",
    "        DAT_NOT DATE NOT NULL,\n",
    "        DAT_SNT DATE\n",
    "    )\n",
    "\"\"\")\n",
    "print(\"   FAT_DEN criada\")\n",
    "\n",
    "conn.commit()\n",
    "print(\"\\nTabelas criadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5",
   "metadata": {},
   "source": [
    "## 5. Carga das Dimensoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "load_dims",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dimensoes...\n",
      "   DIM_TMP: 373\n",
      "   DIM_LOC: 27\n",
      "   DIM_PAC: 123\n",
      "   DIM_CLS: 5\n",
      "   DIM_EVL: 6\n",
      "   DIM_SNT: 12\n",
      "\n",
      "Dimensoes carregadas!\n"
     ]
    }
   ],
   "source": [
    "def load_dim(df, table, cols):\n",
    "    sql = f\"INSERT INTO {table} ({','.join(cols)}) VALUES ({','.join(['%s']*len(cols))})\"\n",
    "    data = [tuple(row[c] if pd.notna(row[c]) else None for c in cols) for _, row in df.iterrows()]\n",
    "    cursor.executemany(sql, data)\n",
    "    conn.commit()\n",
    "    return len(data)\n",
    "\n",
    "print(\"Carregando dimensoes...\")\n",
    "\n",
    "n = load_dim(df_dim_tempo, 'dw.DIM_TMP', ['TMP_SRK','DAT_COM','NUM_ANO','NUM_MES','NUM_DIA','NUM_TRI','NUM_SEM_EPI','NUM_DIA_SEM','NOM_DIA','IND_FDS','DES_MES_ANO','DES_ANO_TRI'])\n",
    "print(f\"   DIM_TMP: {n}\")\n",
    "\n",
    "n = load_dim(df_dim_loc, 'dw.DIM_LOC', ['LOC_SRK','SIG_UNF','NOM_UNF','NOM_REG','COD_IBG','NOM_CAP'])\n",
    "print(f\"   DIM_LOC: {n}\")\n",
    "\n",
    "n = load_dim(df_dim_pac, 'dw.DIM_PAC', ['PAC_SRK','COD_DEM','DES_FAI_ETA','DES_SEX','DES_RAC','DES_FAI_ETA_DET'])\n",
    "print(f\"   DIM_PAC: {n}\")\n",
    "\n",
    "n = load_dim(df_dim_cls, 'dw.DIM_CLS', ['CLS_SRK','COD_CLS','DES_CLS','DES_GRP','DES_GRA','COD_CID','IND_CON'])\n",
    "print(f\"   DIM_CLS: {n}\")\n",
    "\n",
    "n = load_dim(df_dim_evl, 'dw.DIM_EVL', ['EVL_SRK','COD_EVL','DES_EVL','TIP_EVL','IND_OBI','DES_GRA_DES'])\n",
    "print(f\"   DIM_EVL: {n}\")\n",
    "\n",
    "n = load_dim(df_dim_snt, 'dw.DIM_SNT', ['SNT_SRK','COD_SNT','DES_FAI_SNT','DES_FAI_ALR','DES_PER_CLI','IND_SNT','IND_ALR'])\n",
    "print(f\"   DIM_SNT: {n}\")\n",
    "\n",
    "print(\"\\nDimensoes carregadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6",
   "metadata": {},
   "source": [
    "## 6. Criar Lookups e Carregar Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "lookups",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criando lookups...\n",
      "   TMP:373 LOC:27 PAC:123 CLS:5 EVL:6 SNT:12\n"
     ]
    }
   ],
   "source": [
    "print(\"Criando lookups...\")\n",
    "\n",
    "cursor.execute(\"SELECT TMP_SRK, DAT_COM FROM dw.DIM_TMP\")\n",
    "lk_tmp = {row[1]: row[0] for row in cursor.fetchall()}\n",
    "\n",
    "cursor.execute(\"SELECT LOC_SRK, SIG_UNF FROM dw.DIM_LOC\")\n",
    "lk_loc = {row[1]: row[0] for row in cursor.fetchall()}\n",
    "\n",
    "cursor.execute(\"SELECT PAC_SRK, COD_DEM FROM dw.DIM_PAC\")\n",
    "lk_pac = {row[1]: row[0] for row in cursor.fetchall()}\n",
    "\n",
    "cursor.execute(\"SELECT CLS_SRK, DES_CLS FROM dw.DIM_CLS\")\n",
    "lk_cls = {row[1]: row[0] for row in cursor.fetchall()}\n",
    "\n",
    "cursor.execute(\"SELECT EVL_SRK, DES_EVL FROM dw.DIM_EVL\")\n",
    "lk_evl = {row[1]: row[0] for row in cursor.fetchall()}\n",
    "\n",
    "cursor.execute(\"SELECT SNT_SRK, COD_SNT FROM dw.DIM_SNT\")\n",
    "lk_snt = {row[1]: row[0] for row in cursor.fetchall()}\n",
    "\n",
    "print(f\"   TMP:{len(lk_tmp)} LOC:{len(lk_loc)} PAC:{len(lk_pac)} CLS:{len(lk_cls)} EVL:{len(lk_evl)} SNT:{len(lk_snt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "prepare_fact",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparando tabela fato...\n",
      "Fato preparada: 1,661,634 registros\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparando tabela fato...\")\n",
    "\n",
    "df_fato = pd.DataFrame()\n",
    "df_fato['FAT_SRK'] = range(1, len(df_silver) + 1)\n",
    "df_fato['NUM_NOT'] = df_silver['id_notificacao']\n",
    "df_fato['TMP_SRK'] = df_silver['data_notificacao'].apply(lambda x: lk_tmp.get(x, -1) if pd.notna(x) else -1)\n",
    "df_fato['LOC_SRK'] = df_silver['uf_sigla'].apply(lambda x: lk_loc.get(x, -1) if pd.notna(x) else -1)\n",
    "df_fato['PAC_SRK'] = df_silver['COD_DEM'].apply(lambda x: lk_pac.get(x, -1) if pd.notna(x) else -1)\n",
    "df_fato['CLS_SRK'] = df_silver['classificacao_desc'].apply(lambda x: lk_cls.get(x, -1) if pd.notna(x) else -1)\n",
    "df_fato['EVL_SRK'] = df_silver['evolucao_desc'].apply(lambda x: lk_evl.get(x, -1) if pd.notna(x) else -1)\n",
    "df_fato['SNT_SRK'] = df_silver['COD_SNT'].apply(lambda x: lk_snt.get(x, -1) if pd.notna(x) else -1)\n",
    "df_fato['VAL_CON'] = df_silver['fl_confirmado'].fillna(0).astype(int)\n",
    "df_fato['VAL_GRA'] = df_silver['fl_grave'].fillna(0).astype(int)\n",
    "df_fato['VAL_OBI'] = df_silver['fl_obito'].fillna(0).astype(int)\n",
    "df_fato['VAL_HOS'] = df_silver['fl_hospitalizado'].fillna(0).astype(int)\n",
    "df_fato['QTD_SNT'] = df_silver['qtd_sintomas'].fillna(0).astype(int)\n",
    "df_fato['QTD_ALR'] = df_silver['qtd_alarmes'].fillna(0).astype(int)\n",
    "df_fato['VAL_IDA'] = df_silver['idade_anos']\n",
    "df_fato['DAT_NOT'] = df_silver['data_notificacao']\n",
    "df_fato['DAT_SNT'] = df_silver['data_sintomas']\n",
    "\n",
    "print(f\"Fato preparada: {len(df_fato):,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "load_fact",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando 1,661,634 registros em 34 batches...\n",
      "   Batch 1/34: 50,000 (3%)\n",
      "   Batch 2/34: 100,000 (6%)\n",
      "   Batch 3/34: 150,000 (9%)\n",
      "   Batch 4/34: 200,000 (12%)\n",
      "   Batch 5/34: 250,000 (15%)\n",
      "   Batch 6/34: 300,000 (18%)\n",
      "   Batch 7/34: 350,000 (21%)\n",
      "   Batch 8/34: 400,000 (24%)\n",
      "   Batch 9/34: 450,000 (26%)\n",
      "   Batch 10/34: 500,000 (29%)\n",
      "   Batch 11/34: 550,000 (32%)\n",
      "   Batch 12/34: 600,000 (35%)\n",
      "   Batch 13/34: 650,000 (38%)\n",
      "   Batch 14/34: 700,000 (41%)\n",
      "   Batch 15/34: 750,000 (44%)\n",
      "   Batch 16/34: 800,000 (47%)\n",
      "   Batch 17/34: 850,000 (50%)\n",
      "   Batch 18/34: 900,000 (53%)\n",
      "   Batch 19/34: 950,000 (56%)\n",
      "   Batch 20/34: 1,000,000 (59%)\n",
      "   Batch 21/34: 1,050,000 (62%)\n",
      "   Batch 22/34: 1,100,000 (65%)\n",
      "   Batch 23/34: 1,150,000 (68%)\n",
      "   Batch 24/34: 1,200,000 (71%)\n",
      "   Batch 25/34: 1,250,000 (74%)\n",
      "   Batch 26/34: 1,300,000 (76%)\n",
      "   Batch 27/34: 1,350,000 (79%)\n",
      "   Batch 28/34: 1,400,000 (82%)\n",
      "   Batch 29/34: 1,450,000 (85%)\n",
      "   Batch 30/34: 1,500,000 (88%)\n",
      "   Batch 31/34: 1,550,000 (91%)\n",
      "   Batch 32/34: 1,600,000 (94%)\n",
      "   Batch 33/34: 1,650,000 (97%)\n",
      "   Batch 34/34: 1,661,634 (100%)\n",
      "\n",
      "Carga concluida!\n"
     ]
    }
   ],
   "source": [
    "cols = ['FAT_SRK','NUM_NOT','TMP_SRK','LOC_SRK','PAC_SRK','CLS_SRK','EVL_SRK','SNT_SRK',\n",
    "        'VAL_CON','VAL_GRA','VAL_OBI','VAL_HOS','QTD_SNT','QTD_ALR','VAL_IDA','DAT_NOT','DAT_SNT']\n",
    "\n",
    "sql = f\"INSERT INTO dw.FAT_DEN ({','.join(cols)}) VALUES %s\"\n",
    "total = len(df_fato)\n",
    "batches = (total + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "print(f\"Carregando {total:,} registros em {batches} batches...\")\n",
    "\n",
    "for i in range(batches):\n",
    "    start, end = i * BATCH_SIZE, min((i + 1) * BATCH_SIZE, total)\n",
    "    batch = df_fato.iloc[start:end]\n",
    "    data = [tuple(row[c] if pd.notna(row[c]) else None for c in cols) for _, row in batch.iterrows()]\n",
    "    execute_values(cursor, sql, data)\n",
    "    conn.commit()\n",
    "    print(f\"   Batch {i+1}/{batches}: {end:,} ({(i+1)/batches*100:.0f}%)\")\n",
    "\n",
    "print(f\"\\nCarga concluida!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section7",
   "metadata": {},
   "source": [
    "## 7. Validacao Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "validate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDACAO FINAL\n",
      "==================================================\n",
      "\n",
      "Silver: 1,661,634 | Gold: 1,661,634 | OK\n",
      "\n",
      "Confirmados: 1,445,765 | Graves: 37,208 | Obitos: 1,773 | Hosp: 72,684\n",
      "Taxa letalidade: 0.1226% | Taxa gravidade: 2.57%\n"
     ]
    }
   ],
   "source": [
    "print(\"VALIDACAO FINAL\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "cursor.execute(\"SELECT COUNT(*) FROM dw.FAT_DEN\")\n",
    "total_gold = cursor.fetchone()[0]\n",
    "print(f\"\\nSilver: {total_silver:,} | Gold: {total_gold:,} | {'OK' if total_gold==total_silver else 'ERRO'}\")\n",
    "\n",
    "cursor.execute(\"SELECT SUM(VAL_CON), SUM(VAL_GRA), SUM(VAL_OBI), SUM(VAL_HOS) FROM dw.FAT_DEN\")\n",
    "m = cursor.fetchone()\n",
    "print(f\"\\nConfirmados: {m[0]:,} | Graves: {m[1]:,} | Obitos: {m[2]:,} | Hosp: {m[3]:,}\")\n",
    "if m[0] > 0:\n",
    "    print(f\"Taxa letalidade: {m[2]/m[0]*100:.4f}% | Taxa gravidade: {m[1]/m[0]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "top_ufs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOP 5 UFs:\n",
      "   SP (Sao Paulo): 876,832 casos, 1,118 obitos\n",
      "   MG (Minas Gerais): 119,016 casos, 149 obitos\n",
      "   GO (Goias): 96,685 casos, 105 obitos\n",
      "   PR (Parana): 92,514 casos, 145 obitos\n",
      "   RS (Rio Grande do Sul): 44,075 casos, 53 obitos\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTOP 5 UFs:\")\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT l.SIG_UNF, l.NOM_UNF, SUM(f.VAL_CON) as casos, SUM(f.VAL_OBI) as obitos\n",
    "    FROM dw.FAT_DEN f JOIN dw.DIM_LOC l ON f.LOC_SRK = l.LOC_SRK\n",
    "    GROUP BY l.SIG_UNF, l.NOM_UNF ORDER BY casos DESC LIMIT 5\n",
    "\"\"\")\n",
    "for r in cursor.fetchall():\n",
    "    print(f\"   {r[0]} ({r[1]}): {r[2]:,} casos, {r[3]:,} obitos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "close",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ETL SILVER -> GOLD CONCLUIDO!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ETL SILVER -> GOLD CONCLUIDO!\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
